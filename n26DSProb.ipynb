{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Data\n",
      "\n",
      "==========\n",
      "\n",
      "                            user_id transaction_date transaction_type  \\\n",
      "0  a78884f5e76951188c1e719d4956773a       2016-02-01               DT   \n",
      "1  b0333294fef6ff1299102a70ad46b126       2016-02-01               DT   \n",
      "\n",
      "   mcc_group  amount_n26_currency dataset_transaction dataset_user  \n",
      "0        NaN                  350            training     training  \n",
      "1        NaN                  202            training     training  \n",
      "\n",
      "\n",
      "MCC Group Data\n",
      "\n",
      "========\n",
      "\n",
      "   mcc_group explanation\n",
      "0          1         ATM\n",
      "1          2   Groceries\n",
      "\n",
      "\n",
      "Transaction Types Data\n",
      "======\n",
      "\n",
      "  type            explanation direction agent\n",
      "0   AR   Authorization reject         -  Card\n",
      "1   AE  Authorization expired        In  Card\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "master_dataset = pd.read_csv('/data/anuj/JA/2016-09-19_79351_training.csv', delimiter = ',')\n",
    "mcc_group_definition = pd.read_csv('/data/anuj/JA/mcc_group_definition.csv', delimiter = ',')\n",
    "transaction_types = pd.read_csv('/data/anuj/JA/transaction_types.csv', delimiter = ',')\n",
    "\n",
    "print \"Master Data\\n\\n==========\\n\\n\",master_dataset.head(2)\n",
    "print \"\\n\\nMCC Group Data\\n\\n========\\n\\n\",mcc_group_definition.head(2)\n",
    "print \"\\n\\nTransaction Types Data\\n======\\n\\n\",transaction_types.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408546, 7)\n"
     ]
    }
   ],
   "source": [
    "print master_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#a = training.query('user_id == \"a78884f5e76951188c1e719d4956773a\"')\n",
    "\n",
    "#a = set(training['user_id'])\n",
    "\n",
    "'''\n",
    "I am making a model for prdicitng income and expences of individual.\n",
    "\n",
    "So First making two dataset one is only having income and other is only for expencse.\n",
    "'''\n",
    "\n",
    "dict_transaction = {}\n",
    "\n",
    "for i in range(len(transaction_types['type'])):\n",
    "    if(transaction_types['direction'][i]=='In'):\n",
    "                dict_transaction[transaction_types['type'][i]] =1\n",
    "    if(transaction_types['direction'][i]=='Out'):\n",
    "                dict_transaction[transaction_types['type'][i]] =-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408546, 7)\n"
     ]
    }
   ],
   "source": [
    "print master_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FT',\n",
       " 'DI',\n",
       " 'DD',\n",
       " 'WU',\n",
       " 'DT',\n",
       " 'DR',\n",
       " 'PR',\n",
       " 'PT',\n",
       " 'BUS',\n",
       " 'PF',\n",
       " 'BUB',\n",
       " 'AA',\n",
       " 'AE',\n",
       " 'WEE',\n",
       " 'AL',\n",
       " 'AU',\n",
       " 'AV',\n",
       " 'BBU',\n",
       " 'CT',\n",
       " 'BRU',\n",
       " 'TBU',\n",
       " 'TUB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_transaction.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### As transaction_types is not blank I am doing inner join ########\n",
    "######## Could not find data for all transaction type specially for \"-\" ##########\n",
    "transaction_types.columns=[\"transaction_type\", 'explanation', 'direction', 'agent']\n",
    "master_dataset_new=pd.merge(master_dataset,transaction_types,on='transaction_type',how='inner')\n",
    "#transaction_types.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'transaction_date', 'transaction_type', 'mcc_group', 'amount_n26_currency', 'direction', 'agent']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     150222\n",
       "1      69807\n",
       "2      50586\n",
       "6      24672\n",
       "3      20875\n",
       "8      20610\n",
       "4      20194\n",
       "17     11466\n",
       "16     11150\n",
       "7      10888\n",
       "10      7282\n",
       "11      5803\n",
       "5       3337\n",
       "12       873\n",
       "15       329\n",
       "9        287\n",
       "13       141\n",
       "14        24\n",
       "Name: mcc_group, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## removing unwanted columns #############\n",
    "master_dataset_new=master_dataset_new.drop(['explanation','dataset_transaction','dataset_user'], axis=1)\n",
    "########### replcaing mcc_group's value NAN to 0 #########\n",
    "master_dataset_new['mcc_group']=master_dataset_new['mcc_group'].fillna(0).astype(int)\n",
    "print master_dataset_new.columns.tolist()\n",
    "master_dataset_new['mcc_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out    336421\n",
       "In      72125\n",
       "Name: direction, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset_new['direction'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>mcc_group</th>\n",
       "      <th>amount_n26_currency</th>\n",
       "      <th>direction</th>\n",
       "      <th>agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a78884f5e76951188c1e719d4956773a</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bank Account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0333294fef6ff1299102a70ad46b126</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bank Account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7b8d2a2780adae0cd0c248e92c1b28dc</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bank Account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc4abaa500f7db4390ae3f02bd36d805</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bank Account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49b99d1d5ba028566639e8b3eb7c055b</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bank Account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id transaction_date transaction_type  \\\n",
       "0  a78884f5e76951188c1e719d4956773a       2016-02-01               DT   \n",
       "1  b0333294fef6ff1299102a70ad46b126       2016-02-01               DT   \n",
       "2  7b8d2a2780adae0cd0c248e92c1b28dc       2016-02-01               DT   \n",
       "3  cc4abaa500f7db4390ae3f02bd36d805       2016-02-01               DT   \n",
       "4  49b99d1d5ba028566639e8b3eb7c055b       2016-02-01               DT   \n",
       "\n",
       "   mcc_group  amount_n26_currency direction         agent  \n",
       "0          0                  350       Out  Bank Account  \n",
       "1          0                  202       Out  Bank Account  \n",
       "2          0                  291       Out  Bank Account  \n",
       "3          0                  214       Out  Bank Account  \n",
       "4          0                  272       Out  Bank Account  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_type_Id transaction_type\n",
      "0                    0               DT\n",
      "1                    1               CT\n",
      "2                    2               DR\n",
      "3                    3               FT\n",
      "4                    4               DD\n",
      "5                    5               PT\n",
      "6                    6              BBU\n",
      "7                    7              BUB\n",
      "8                    8              TUB\n",
      "   agent_Id         agent\n",
      "0         0  Bank Account\n",
      "1         1          Card\n",
      "2         2       Partner\n"
     ]
    }
   ],
   "source": [
    "############# converting index for string features such as transaction_type and agent ########\n",
    "transaction_type_map=pd.DataFrame(master_dataset_new.transaction_type.unique().tolist()).reset_index()\n",
    "transaction_type_map.columns=['transaction_type_Id','transaction_type']\n",
    "print transaction_type_map\n",
    "agent_map=pd.DataFrame(master_dataset_new.agent.unique().tolist()).reset_index()\n",
    "agent_map.columns=['agent_Id','agent']\n",
    "print agent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Replacing the values ###############\n",
    "master_dataset_new1=pd.merge(master_dataset_new,transaction_type_map,on='transaction_type',how='inner')\n",
    "master_dataset_new=pd.merge(master_dataset_new1,agent_map,on='agent',how='inner')\n",
    "########## removing unwanted columns #############\n",
    "master_dataset_new=master_dataset_new.drop(['agent','transaction_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>mcc_group</th>\n",
       "      <th>amount_n26_currency</th>\n",
       "      <th>direction</th>\n",
       "      <th>transaction_type_Id</th>\n",
       "      <th>agent_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a78884f5e76951188c1e719d4956773a</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>Out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0333294fef6ff1299102a70ad46b126</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>Out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7b8d2a2780adae0cd0c248e92c1b28dc</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>Out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc4abaa500f7db4390ae3f02bd36d805</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>Out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49b99d1d5ba028566639e8b3eb7c055b</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>Out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id transaction_date  mcc_group  \\\n",
       "0  a78884f5e76951188c1e719d4956773a       2016-02-01          0   \n",
       "1  b0333294fef6ff1299102a70ad46b126       2016-02-01          0   \n",
       "2  7b8d2a2780adae0cd0c248e92c1b28dc       2016-02-01          0   \n",
       "3  cc4abaa500f7db4390ae3f02bd36d805       2016-02-01          0   \n",
       "4  49b99d1d5ba028566639e8b3eb7c055b       2016-02-01          0   \n",
       "\n",
       "   amount_n26_currency direction  transaction_type_Id  agent_Id  \n",
       "0                  350       Out                    0         0  \n",
       "1                  202       Out                    0         0  \n",
       "2                  291       Out                    0         0  \n",
       "3                  214       Out                    0         0  \n",
       "4                  272       Out                    0         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTRAIN Income\n",
      "\n",
      "                                user_id transaction_date  mcc_group  \\\n",
      "40528  77a52d4da43d0106d321cdc1364bfe01       2016-02-01          0   \n",
      "40529  f70f8ff785fac332a46323ab174082e2       2016-02-01          0   \n",
      "\n",
      "       amount_n26_currency direction  transaction_type_Id  agent_Id  \n",
      "40528                   24        In                    1         0  \n",
      "40529                   38        In                    1         0  \n",
      "XTRAIN Expense\n",
      "\n",
      "                            user_id transaction_date  mcc_group  \\\n",
      "0  a78884f5e76951188c1e719d4956773a       2016-02-01          0   \n",
      "1  b0333294fef6ff1299102a70ad46b126       2016-02-01          0   \n",
      "\n",
      "   amount_n26_currency direction  transaction_type_Id  agent_Id  \n",
      "0                  350       Out                    0         0  \n",
      "1                  202       Out                    0         0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "master_dataset_new['transaction_date'] = pd.to_datetime(master_dataset_new['transaction_date']) \n",
    "############# Taking Income(x_train_in) and expense(x_train_out) data seperately #########\n",
    "x_train_in = master_dataset_new.query('direction == \"In\"')\n",
    "print \"XTRAIN Income\\n\\n\",x_train_in.head(2)\n",
    "x_train_out = master_dataset_new.query('direction == \"Out\"')\n",
    "print \"XTRAIN Expense\\n\\n\",x_train_out.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mcc_group  amount_n26_currency  transaction_type_Id       agent_Id\n",
      "count  336421.000000        336421.000000        336421.000000  336421.000000\n",
      "mean        3.716566            34.282845             4.277718       0.774827\n",
      "std         4.499277            70.930619             1.635168       0.425956\n",
      "min         0.000000             3.000000             0.000000       0.000000\n",
      "25%         1.000000             7.000000             5.000000       1.000000\n",
      "50%         2.000000            14.000000             5.000000       1.000000\n",
      "75%         6.000000            30.000000             5.000000       1.000000\n",
      "max        17.000000          1166.000000             8.000000       2.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72125 entries, 40528 to 407373\n",
      "Data columns (total 7 columns):\n",
      "user_id                72125 non-null object\n",
      "transaction_date       72125 non-null datetime64[ns]\n",
      "mcc_group              72125 non-null int64\n",
      "amount_n26_currency    72125 non-null int64\n",
      "direction              72125 non-null object\n",
      "transaction_type_Id    72125 non-null int64\n",
      "agent_Id               72125 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print x_train_out.describe()\n",
    "x_train_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslib.Timestamp'> <class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "#feature creation:\n",
    "\n",
    "#I will train this model on last four month data    \n",
    "######Intialization for the feature creation ########\n",
    "\n",
    "date=min(master_dataset_new['transaction_date'])\n",
    "#date=datetime.date(*(int(s) for s in date1.split('-'))) #datetime.date(*(int(s) for s in t.split('-')))\n",
    "cut_off_date  = date +  datetime.timedelta(days=(60))\n",
    "print type(cut_off_date),type(date)\n",
    "##### cut_off_date is being taken for removing the biased data #########\n",
    "f_train_x_out = []\n",
    "f_train_y_out = []\n",
    "\n",
    "f_train_x_in = []\n",
    "f_train_y_in = []  \n",
    "\n",
    "sum1 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### creating Data frame of all users ##########\n",
    "userAll=pd.DataFrame(master_dataset_new.user_id.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user processing\n",
      "100\n",
      "user processing\n",
      "200\n",
      "user processing\n",
      "300\n",
      "user processing\n",
      "400\n",
      "user processing\n",
      "500\n",
      "user processing\n",
      "600\n",
      "user processing\n",
      "700\n",
      "user processing\n",
      "800\n",
      "user processing\n",
      "900\n",
      "user processing\n",
      "1000\n",
      "user processing\n",
      "1100\n",
      "user processing\n",
      "1200\n",
      "user processing\n",
      "1300\n",
      "user processing\n",
      "1400\n",
      "user processing\n",
      "1500\n",
      "user processing\n",
      "1600\n",
      "user processing\n",
      "1700\n",
      "user processing\n",
      "1800\n",
      "user processing\n",
      "1900\n",
      "user processing\n",
      "2000\n",
      "user processing\n",
      "2100\n",
      "user processing\n",
      "2200\n",
      "user processing\n",
      "2300\n",
      "user processing\n",
      "2400\n",
      "user processing\n",
      "2500\n",
      "user processing\n",
      "2600\n",
      "user processing\n",
      "2700\n",
      "user processing\n",
      "2800\n",
      "user processing\n",
      "2900\n",
      "user processing\n",
      "3000\n",
      "user processing\n",
      "3100\n",
      "user processing\n",
      "3200\n",
      "user processing\n",
      "3300\n",
      "user processing\n",
      "3400\n",
      "user processing\n",
      "3500\n",
      "user processing\n",
      "3600\n",
      "user processing\n",
      "3700\n",
      "user processing\n",
      "3800\n",
      "user processing\n",
      "3900\n",
      "user processing\n",
      "4000\n",
      "user processing\n",
      "4100\n",
      "user processing\n",
      "4200\n",
      "user processing\n",
      "4300\n",
      "user processing\n",
      "4400\n",
      "user processing\n",
      "4500\n",
      "user processing\n",
      "4600\n",
      "user processing\n",
      "4700\n",
      "user processing\n",
      "4800\n",
      "user processing\n",
      "4900\n",
      "user processing\n",
      "5000\n",
      "user processing\n",
      "5100\n",
      "user processing\n",
      "5200\n",
      "user processing\n",
      "5300\n",
      "user processing\n",
      "5400\n",
      "user processing\n",
      "5500\n",
      "user processing\n",
      "5600\n",
      "user processing\n",
      "5700\n",
      "user processing\n",
      "5800\n",
      "user processing\n",
      "5900\n",
      "user processing\n",
      "6000\n",
      "user processing\n",
      "6100\n",
      "user processing\n",
      "6200\n",
      "user processing\n",
      "6300\n",
      "user processing\n",
      "6400\n",
      "user processing\n",
      "6500\n",
      "user processing\n",
      "6600\n",
      "user processing\n",
      "6700\n",
      "user processing\n",
      "6800\n",
      "user processing\n",
      "6900\n",
      "user processing\n",
      "7000\n",
      "user processing\n",
      "7100\n",
      "user processing\n",
      "7200\n",
      "user processing\n",
      "7300\n",
      "user processing\n",
      "7400\n",
      "user processing\n",
      "7500\n",
      "user processing\n",
      "7600\n",
      "user processing\n",
      "7700\n",
      "user processing\n",
      "7800\n",
      "user processing\n",
      "7900\n",
      "user processing\n",
      "8000\n",
      "user processing\n",
      "8100\n",
      "user processing\n",
      "8200\n",
      "user processing\n",
      "8300\n"
     ]
    }
   ],
   "source": [
    "sum1 = 0\n",
    "for uid in userAll[0]:\n",
    "    sum1 +=1\n",
    "    if(sum1%100==0):\n",
    "        print 'user processing'\n",
    "        print sum1\n",
    "    my_symbol = [uid]\n",
    "    out_data = x_train_out.query('user_id == @my_symbol ' )\n",
    "    out_data = out_data.groupby('transaction_date').sum().reset_index()\n",
    "    in_data  = x_train_in.query('user_id == @my_symbol ' )\n",
    "    in_data = in_data.groupby('transaction_date').sum().reset_index()  \n",
    "    for date in in_data['transaction_date']:\n",
    "      if(date>cut_off_date):\n",
    "          train_x_out = []\n",
    "          train_x_in = []\n",
    "          train_y_out = []      \n",
    "          train_y_in = []  \n",
    "                \n",
    "          date1  = date +  datetime.timedelta(days=(-90))  \n",
    "          df  = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f1_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f1_in = sum(df['amount_n26_currency'])\n",
    "        \n",
    "          train_x_out.append(f1_out)\n",
    "          train_x_out.append(f1_in)\n",
    "          train_x_in.append(f1_in)\n",
    "          train_x_in.append(f1_out)\n",
    "   \n",
    "        \n",
    "          mcc_group_in=in_data.query('transaction_date==@date')['mcc_group']\n",
    "          transaction_type_in=in_data.query('transaction_date==@date')['transaction_type_Id']\n",
    "          agent_in=in_data.query('transaction_date==@date')['agent_Id']#agent_Id  \n",
    "        \n",
    "          train_x_in.append(int(mcc_group_in))\n",
    "          train_x_in.append(int(transaction_type_in))\n",
    "          train_x_in.append(int(transaction_type_in))\n",
    "            ##################\n",
    "          date1  = date +  datetime.timedelta(days=(-30))  \n",
    "          df = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f2_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f2_in = sum(df['amount_n26_currency'])\n",
    "          train_x_out.append(f2_out)\n",
    "          train_x_out.append(f2_in)\n",
    "          train_x_in.append(f2_in)\n",
    "          train_x_in.append(f2_out)\n",
    "        \n",
    "          date1  = date +  datetime.timedelta(days=(-7))  \n",
    "          df = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f3_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f3_in = sum(df['amount_n26_currency'])\n",
    "          train_x_out.append(f3_out)\n",
    "          train_x_out.append(f3_in)\n",
    "          train_x_in.append(f3_in)\n",
    "          train_x_in.append(f3_out)\n",
    "            \n",
    "          date1  = date +  datetime.timedelta(days=(-2))  \n",
    "          df = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f4_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f4_in = sum(df['amount_n26_currency'])\n",
    "          train_x_out.append(f4_out)\n",
    "          train_x_out.append(f4_in)\n",
    "          train_x_in.append(f4_in)\n",
    "          train_x_in.append(f4_out)\n",
    "          \n",
    "          #date1  = date +  datetime.timedelta(days=(-30))  \n",
    "          last_30_days = f2_out\n",
    "          avg_last_90_days = f1_out/3.0\n",
    "          standard = sum(out_data['amount_n26_currency'])/6.0\n",
    "          f5_out = (last_30_days-avg_last_90_days)/6.0\n",
    "          \n",
    "          last_30_days = f2_in\n",
    "          avg_last_90_days = f1_in/3.0\n",
    "          standard = sum(in_data['amount_n26_currency'])/6.0\n",
    "          f5_in = (last_30_days-avg_last_90_days)/6.0\n",
    "          train_x_out.append(f5_out)\n",
    "          train_x_out.append(f5_in)\n",
    "          train_x_in.append(f5_in)\n",
    "          train_x_in.append(f5_out)\n",
    "            \n",
    "          df = out_data[(out_data['transaction_date'] == date)]\n",
    "          train_y_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date'] == date)]\n",
    "          train_y_in = sum(df['amount_n26_currency'])\n",
    "          f_train_x_in.append(train_x_in)\n",
    "          f_train_y_in.append(train_y_in)\n",
    "        \n",
    "    for date in out_data['transaction_date']:\n",
    "      if(date>cut_off_date):\n",
    "          train_x_out = []\n",
    "          train_x_in = []\n",
    "          train_y_out = []      \n",
    "          train_y_in = []  \n",
    "                \n",
    "          date1  = date +  datetime.timedelta(days=(-90))  \n",
    "          df  = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f1_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f1_in = sum(df['amount_n26_currency'])\n",
    "        \n",
    "          train_x_out.append(f1_out)\n",
    "          train_x_out.append(f1_in)\n",
    "          train_x_in.append(f1_in)\n",
    "          train_x_in.append(f1_out)\n",
    "          ##########\n",
    "          mcc_group_out=out_data.query('transaction_date==@date')['mcc_group']\n",
    "          transaction_type_out=out_data.query('transaction_date==@date')['transaction_type_Id']\n",
    "          agent_out=out_data.query('transaction_date==@date')['agent_Id']#agent_Id  \n",
    "        \n",
    "          train_x_out.append(int(mcc_group_out))\n",
    "          train_x_out.append(int(transaction_type_out))\n",
    "          train_x_out.append(int(agent_out))\n",
    "\n",
    "            ##################\n",
    "          date1  = date +  datetime.timedelta(days=(-30))  \n",
    "          df = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f2_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f2_in = sum(df['amount_n26_currency'])\n",
    "          train_x_out.append(f2_out)\n",
    "          train_x_out.append(f2_in)\n",
    "          train_x_in.append(f2_in)\n",
    "          train_x_in.append(f2_out)\n",
    "        \n",
    "          date1  = date +  datetime.timedelta(days=(-7))  \n",
    "          df = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f3_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f3_in = sum(df['amount_n26_currency'])\n",
    "          train_x_out.append(f3_out)\n",
    "          train_x_out.append(f3_in)\n",
    "          train_x_in.append(f3_in)\n",
    "          train_x_in.append(f3_out)\n",
    "            \n",
    "          date1  = date +  datetime.timedelta(days=(-2))  \n",
    "          df = out_data[(out_data['transaction_date']> date1) & (out_data['transaction_date']<= date)]\n",
    "          f4_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date']> date1) & (in_data['transaction_date']<= date)]\n",
    "          f4_in = sum(df['amount_n26_currency'])\n",
    "          train_x_out.append(f4_out)\n",
    "          train_x_out.append(f4_in)\n",
    "          train_x_in.append(f4_in)\n",
    "          train_x_in.append(f4_out)\n",
    "          \n",
    "          #date1  = date +  datetime.timedelta(days=(-30))  \n",
    "          last_30_days = f2_out\n",
    "          avg_last_90_days = f1_out/3.0\n",
    "          standard = sum(out_data['amount_n26_currency'])/6.0\n",
    "          f5_out = (last_30_days-avg_last_90_days)/6.0\n",
    "          \n",
    "          last_30_days = f2_in\n",
    "          avg_last_90_days = f1_in/3.0\n",
    "          standard = sum(in_data['amount_n26_currency'])/6.0\n",
    "          f5_in = (last_30_days-avg_last_90_days)/6.0\n",
    "          train_x_out.append(f5_out)\n",
    "          train_x_out.append(f5_in)\n",
    "          train_x_in.append(f5_in)\n",
    "          train_x_in.append(f5_out)\n",
    "            \n",
    "          df = out_data[(out_data['transaction_date'] == date)]\n",
    "          train_y_out = sum(df['amount_n26_currency'])\n",
    "          df = in_data[(in_data['transaction_date'] == date)]\n",
    "          train_y_in = sum(df['amount_n26_currency'])\n",
    "          #print train_x_out\n",
    "          f_train_x_out.append(train_x_out)\n",
    "          f_train_y_out.append(train_y_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear r squared 0.917846939354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3858.9241347532288"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression() \n",
    "#regr= LinearRegression()\n",
    "lm.fit(f_train_x_in, f_train_y_in)\n",
    "\n",
    "print \"linear r squared\",lm.score(f_train_x_in,f_train_y_in)\n",
    "predictions = lm.predict(f_train_x_in)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(f_train_y_in, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42311, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(f_train_x_in).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Creating the training and testing set ###################\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_in, X_test_in, y_train_in, y_test_in = train_test_split(f_train_x_in, f_train_y_in, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------lm---- 0.915104488624\n",
      "---lm--- 3865.92418701\n",
      "---RandF--- 3479.04777743\n",
      "---RandF--- 0.923600276188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/ActivePython-2.7.13/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---XgBoost--- 3636.04635022\n",
      "---XgBoost--- 0.920152594993\n",
      "---Neural--- 3892.83594879\n",
      "---Neural--- 0.914513507615\n",
      "---GBM--- 3604.5705536\n",
      "---GBM--- 0.92084380199\n"
     ]
    }
   ],
   "source": [
    "################### trying lm ################\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression() \n",
    "#regr= LinearRegression()\n",
    "lm.fit(X_train_in, y_train_in)\n",
    "\n",
    "prediction_lm=lm.predict(X_test_in)\n",
    "print \"------lm----\",lm.score(X_test_in,y_test_in)\n",
    "print \"---lm---\",mean_squared_error(y_test_in, prediction_lm)\n",
    "\n",
    "#regr.score(X_test_in,y_test_in)\n",
    "\n",
    "################### trying Random Forest ################\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=25, random_state=0,n_estimators =15,)\n",
    "regr.fit(X_train_in, y_train_in)\n",
    "prediction_randF=regr.predict(X_test_in)\n",
    "print \"---RandF---\",mean_squared_error(y_test_in, prediction_randF)\n",
    "print \"---RandF---\", regr.score(X_test_in,y_test_in)\n",
    "\n",
    "################### XgBoost ####################\n",
    "from xgboost import XGBRegressor \n",
    "xgbs= XGBRegressor(\n",
    "            seed=10,\n",
    "            n_estimators=500, max_depth=50,\n",
    "            learning_rate=0.05, subsample=0.8, colsample_bytree=0.75\n",
    "        )\n",
    "xgbs.fit(X_train_in, y_train_in)\n",
    "prediction_xgb=xgbs.predict(X_test_in)\n",
    "print \"---XgBoost---\", mean_squared_error(y_test_in, prediction_xgb)  \n",
    "print \"---XgBoost---\", xgbs.score(X_test_in,y_test_in)\n",
    "\n",
    "############## Neural Net Regression ##########\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clfN2 = MLPRegressor(solver='adam', alpha=.001,activation =\"relu\",\n",
    "                    hidden_layer_sizes=(128,64,32,16), random_state=2,max_iter=5000)\n",
    "\n",
    "clfN2.fit(X_train_in, y_train_in)\n",
    "prediction_neuralNet2 = clfN2.predict(X_test_in)\n",
    "print \"---Neural---\",mean_squared_error(y_test_in, prediction_neuralNet2)\n",
    "print \"---Neural---\", clfN2.score(X_test_in,y_test_in)\n",
    "\n",
    "########## Gradient Boosting machine ###########\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingClassifier,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "gbr=GradientBoostingRegressor(\n",
    "            random_state=0, \n",
    "            n_estimators=500, max_depth=10,\n",
    "            learning_rate=0.05, subsample=0.8\n",
    "        )\n",
    "gbr.fit(X_train_in, y_train_in)\n",
    "prediction_gbr=gbr.predict(X_test_in)\n",
    "#mean_squared_error(y_test_in, prediction_gbr) \n",
    "print \"---GBM---\",mean_squared_error(y_test_in, prediction_gbr) \n",
    "print \"---GBM---\", gbr.score(X_test_in,y_test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Creating the training and testing set ###################\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_out, X_test_out, y_train_out, y_test_out = train_test_split(f_train_x_out, f_train_y_out, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---lm--- 0.705834239232\n",
      "---lm--- 3192.53155236\n",
      "---RandF--- 3245.60622534\n",
      "---RandF--- 0.700943840721\n",
      "---XgBoost--- 3279.52629709\n",
      "---XgBoost--- 0.697818382585\n",
      "---Neural--- 3240.3091072\n",
      "---Neural--- 0.701431926981\n"
     ]
    }
   ],
   "source": [
    "################### trying lm ################\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression() \n",
    "#regr= LinearRegression()\n",
    "lm.fit(X_train_out, y_train_out)\n",
    "\n",
    "prediction_lm=lm.predict(X_test_out)\n",
    "print \"---lm---\",lm.score(X_test_out,y_test_out)\n",
    "print \"---lm---\",mean_squared_error(y_test_out, prediction_lm)\n",
    "\n",
    "#regr.score(X_test_out,y_test_out)\n",
    "\n",
    "################### trying Random Forest ################\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=25, random_state=0,n_estimators =15,)\n",
    "regr.fit(X_train_out, y_train_out)\n",
    "prediction_randF=regr.predict(X_test_out)\n",
    "print \"---RandF---\",mean_squared_error(y_test_out, prediction_randF)\n",
    "print \"---RandF---\", regr.score(X_test_out,y_test_out)\n",
    "\n",
    "################### XgBoost ####################\n",
    "from xgboost import XGBRegressor \n",
    "xgbs= XGBRegressor(\n",
    "            seed=10,\n",
    "            n_estimators=500, max_depth=50,\n",
    "            learning_rate=0.05, subsample=0.8, colsample_bytree=0.75\n",
    "        )\n",
    "xgbs.fit(X_train_out, y_train_out)\n",
    "prediction_xgb=xgbs.predict(X_test_out)\n",
    "print \"---XgBoost---\", mean_squared_error(y_test_out, prediction_xgb)  \n",
    "print \"---XgBoost---\", xgbs.score(X_test_out,y_test_out)\n",
    "\n",
    "############## Neural Net Regression ##########\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clfN2 = MLPRegressor(solver='adam', alpha=.001,activation =\"relu\",\n",
    "                    hidden_layer_sizes=(128,64,32,16), random_state=2,max_iter=5000)\n",
    "\n",
    "clfN2.fit(X_train_out, y_train_out)\n",
    "prediction_neuralNet2 = clfN2.predict(X_test_out)\n",
    "print \"---Neural---\",mean_squared_error(y_test_out, prediction_neuralNet2)\n",
    "print \"---Neural---\", clfN2.score(X_test_out,y_test_out)\n",
    "\n",
    "########## Gradient Boosting machine ###########\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingClassifier,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "gbr=GradientBoostingRegressor(\n",
    "            random_state=0, \n",
    "            n_estimators=500, max_depth=10,\n",
    "            learning_rate=0.05, subsample=0.8\n",
    "        )\n",
    "gbr.fit(X_train_out, y_train_out)\n",
    "prediction_gbr=gbr.predict(X_test_out)\n",
    "#mean_squared_error(y_test_out, prediction_gbr) \n",
    "print \"---GBM---\",mean_squared_error(y_test_out, prediction_gbr) \n",
    "print \"---GBM---\", gbr.score(X_test_out,y_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
